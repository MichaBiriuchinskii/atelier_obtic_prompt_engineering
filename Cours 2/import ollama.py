import ollama

def call_ollama(prompt: str, temperature: float = 0.1):
    """
    Appelle un mod√®le local via Ollama et retourne la r√©ponse.

    Args:
        prompt: Le texte d'entr√©e
        temperature: Niveau de cr√©ativit√© (0.1 = peu cr√©atif, 1 = tr√®s cr√©atif)

    Returns:
        La r√©ponse du mod√®le (ex: 'llama3')
    """
    try:
        response = ollama.chat(
            model='llama3.2',  
            messages=[{"role": "user", "content": prompt}],
            options={"temperature": temperature}
        )

        result = response.get("message", {}).get("content", "").strip()

        if result.startswith(prompt):
            result = result[len(prompt):].strip()

        return result

    except Exception as e:
        return f"Erreur: {e}"

prompt = """Salut, √ßa va ? 
"""

response = call_ollama(prompt)

print(f"üìú Prompt: {prompt}")
print(f"üìù R√©ponse: {response}")
